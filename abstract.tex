%----------------------------------------------------------------------------
% Abstract in hungarian
%----------------------------------------------------------------------------
\chapter*{Kivonat}\addcontentsline{toc}{chapter}{Kivonat}

Diplomamunkám során annak a lehet\H{o}ségét vizsgálom, lehetséges-e  gráftranszformációként értelmezni a természetes nyelvfeldolgozásban kivonatolással létrehozott összefoglalásként ismert feladatot és gráf neurális hálót építeni ezen feadat megoldására a DeepMind graph\_nets könyvtárát felhasználva.

Kivonatolással létrehozott összefoglalás (angolul extractive summarization) alatt azt a feladatot értjük, amely során egy szöveghez összefoglalót képzünk a szövegben szerepl\H{o} szavak, kifejezések és modatok felhasználásával.
\rg{csak mondatok!}

Munk\'am során megvalósítottam egy leképzést, mely cikkekb\H{o}l megfelel\H{o} universal dependency (UD) gráfot generál a stanfordnlp könyvtár felhasználásával. Mivel a gráfok tanulásakor feltétel, hogy az élek és csúcsok száma megyegyezzen, így az összefoglalóhoz képzett gráfot ennek megfelel\H{o}en alakítottam ki.
\rg{mármint a bemenet és kimenet éleinek és csúcsainak száma, páronként, nem?
Így most nem érthet\H{o}}

A graph\_nets könyvtár tartalmaz egy Encode-Process-Decode modellt, amelyet kiindulási alapnak tudtam felhasználni munkám során. Több módszerrel is megvizsgáltam ezen modell használhatóságát a feladaton, majd az így szerzett tapaszalatokkal építettem egy másik gráf neurális hálót, természetes nyelvfeldolgozás feladatok megoldására szabva.

A gráf neurális hálók tanítása kihívásokkal teli feladatnak bizonyult, mivel felépítése eltér a megszokott neurális háló struktúráktól.

Az eredményeimet az adathalmazhoz tartozó szabad szavas összefoglalóhoz mértem, ezzel meghatározva a ROUGE pontját, valamint ezt összevetettem a kivonatolással elérhet\H{o} maximum ROUGE ponttal és a gensim könyvtár kulcsszó alapú összefoglalójával.

%----------------------------------------------------------------------------
% Abstract in english
%----------------------------------------------------------------------------
\chapter*{Abstract}\addcontentsline{toc}{chapter}{Abstract}

In my masters thesis I examined the possibility of using graph transformations for a natural language processing task known as extractive summarization and whether we could build a graph neural network for this purpose using DeepMind's graph\_nets library.

Extractive summarization is the task of generating a summary for a text using only the words, expressions and/or sentences from the original text.

I've worked out a method to transform the articles into their respective universal dependency (UD) graph using the stanfordnlp library. Since the structure of input and output graphs are required to be the same for the graph neural networks to be able to train on them I had to modify the graphs built from the summary accordingly.
\rg{nem "worked out", az azt jelentené, hogy Te találtad ki, hogyan kell
dependencia-parszolni}


The graph\_nets library already contains an Encode-Process-Decode model that proved to be a great starting point while exploring the task and possibilities. I experimented with the usability of this model on my task and with the observations I gathered I have build an other graph neural network specifically for solving natural language processing tasks.

The training these graphs was a challenging task, because their structure vastly differs from regular neural networks.

I compared the achieved results with the free form summaries provided in the dataset determining its ROUGE score. This score was compared with the maximum achievable ROUGE score with extractive summarization and also with the summary generated by gensim's textrank algorithm.
